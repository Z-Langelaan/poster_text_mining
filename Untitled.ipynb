{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ce6e13c-f85a-4c02-b852-43129f461ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\feter\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.sentiment import vader\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "import pandas\n",
    "import pathlib\n",
    "import numpy\n",
    "from collections import Counter\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm') # 'en_core_web_sm'\n",
    "nltk.download('stopwords')\n",
    "vader_model = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a88d0b42-d6cb-47f6-9c95-e631686d0de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path  = pandas.read_csv('C:/Users/feter/OneDrive/Bureaublad/AI/AI Year 3/p4/text mining/sentiment-topic-test.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0eae028-2532-4adc-abd5-4c6fcd928b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#kaggle_dataset = pandas.read_csv(path, encoding= 'unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bcd20be-93aa-4a10-97ca-1e70ef41c0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sent in path:\n",
    "#     scores = vader_model.polarity_scores(sent)\n",
    "#     print()\n",
    "#     print('INPUT SENTENCE', sent)\n",
    "#     print('VADER OUTPUT', scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ff253c9-4b27-4170-9f82-783d3237459f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_vader(textual_unit, \n",
    "              lemmatize=False, \n",
    "              parts_of_speech_to_consider=None,\n",
    "              verbose=0):\n",
    "    \"\"\"\n",
    "    Run VADER on a sentence from spacy\n",
    "    \n",
    "    :param str textual unit: a textual unit, e.g., sentence, sentences (one string)\n",
    "    (by looping over doc.sents)\n",
    "    :param bool lemmatize: If True, provide lemmas to VADER instead of words\n",
    "    :param set parts_of_speech_to_consider:\n",
    "    -None or empty set: all parts of speech are provided\n",
    "    -non-empty set: only these parts of speech are considered.\n",
    "    :param int verbose: if set to 1, information is printed\n",
    "    about input and output\n",
    "    \n",
    "    :rtype: dict\n",
    "    :return: vader output dict\n",
    "    \"\"\"\n",
    "    doc = nlp(textual_unit)\n",
    "        \n",
    "    input_to_vader = []\n",
    "\n",
    "    for sent in doc.sents:\n",
    "        for token in sent:\n",
    "\n",
    "            to_add = token.text\n",
    "\n",
    "            if lemmatize:\n",
    "                to_add = token.lemma_\n",
    "\n",
    "                if to_add == '-PRON-': \n",
    "                    to_add = token.text\n",
    "\n",
    "            if parts_of_speech_to_consider:\n",
    "                if token.pos_ in parts_of_speech_to_consider:\n",
    "                    input_to_vader.append(to_add) \n",
    "            else:\n",
    "                input_to_vader.append(to_add)\n",
    "\n",
    "    scores = vader_model.polarity_scores(' '.join(input_to_vader))\n",
    "    \n",
    "    if verbose >= 1:\n",
    "        print()\n",
    "        print('INPUT SENTENCE', sent)\n",
    "        print('INPUT TO VADER', input_to_vader)\n",
    "        print('VADER OUTPUT', scores)\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a9289fb-1e26-4432-8206-7e059992fab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vader_output_to_label(vader_output):\n",
    "    \"\"\"\n",
    "    map vader output e.g.,\n",
    "    {'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.4215}\n",
    "    to one of the following values:\n",
    "    a) positive float -> 'positive'\n",
    "    b) 0.0 -> 'neutral'\n",
    "    c) negative float -> 'negative'\n",
    "    \n",
    "    :param dict vader_output: output dict from vader\n",
    "    \n",
    "    :rtype: str\n",
    "    :return: 'negative' | 'neutral' | 'positive'\n",
    "    \"\"\"\n",
    "    compound = vader_output['compound']\n",
    "    \n",
    "    if compound < 0:\n",
    "        return 'negative'\n",
    "    elif compound == 0.0:\n",
    "        return 'neutral'\n",
    "    elif compound > 0.0:\n",
    "        return 'positive'\n",
    "    \n",
    "assert vader_output_to_label( {'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.0}) == 'neutral'\n",
    "assert vader_output_to_label( {'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.01}) == 'positive'\n",
    "assert vader_output_to_label( {'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': -0.01}) == 'negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d73fa113-2aed-4a17-8cd0-27eb9d8db9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INPUT SENTENCE I wouldn't be caught dead watching the NFL if it weren't for Taylor Swift.\n",
      "INPUT TO VADER ['I', 'would', 'not', 'be', 'catch', 'dead', 'watch', 'the', 'NFL', 'if', 'it', 'be', 'not', 'for', 'Taylor', 'Swift', '.']\n",
      "VADER OUTPUT {'neg': 0.088, 'neu': 0.721, 'pos': 0.191, 'compound': 0.431}\n",
      "positive\n",
      "\n",
      "INPUT SENTENCE Chris O'Donnell stated that while filming for this movie, he felt like he was in a Toys ''R'' Us commercial.\n",
      "INPUT TO VADER ['Chris', \"O'Donnell\", 'state', 'that', 'while', 'film', 'for', 'this', 'movie', ',', 'he', 'feel', 'like', 'he', 'be', 'in', 'a', 'Toys', \"''\", 'R', \"''\", 'Us', 'commercial', '.']\n",
      "VADER OUTPUT {'neg': 0.0, 'neu': 0.884, 'pos': 0.116, 'compound': 0.3612}\n",
      "positive\n",
      "\n",
      "INPUT SENTENCE The whole game was a rollercoaster ride, but Los Angeles Lakers ultimately persevered and won!\n",
      "INPUT TO VADER ['the', 'whole', 'game', 'be', 'a', 'rollercoaster', 'ride', ',', 'but', 'Los', 'Angeles', 'Lakers', 'ultimately', 'persevere', 'and', 'win', '!']\n",
      "VADER OUTPUT {'neg': 0.0, 'neu': 0.703, 'pos': 0.297, 'compound': 0.7574}\n",
      "positive\n",
      "\n",
      "INPUT SENTENCE Zendaya slayed in Dune 2, as she does in all her movies.\n",
      "INPUT TO VADER ['Zendaya', 'slay', 'in', 'Dune', '2', ',', 'as', 'she', 'do', 'in', 'all', 'her', 'movie', '.']\n",
      "VADER OUTPUT {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "neutral\n",
      "\n",
      "INPUT SENTENCE While my favorite player was playing this match and started off strongggg, it went downhill after Messi's injyry midgame.\n",
      "INPUT TO VADER ['while', 'my', 'favorite', 'player', 'be', 'play', 'this', 'match', 'and', 'start', 'off', 'strongggg', ',', 'it', 'go', 'downhill', 'after', 'Messi', \"'s\", 'injyry', 'midgame', '.']\n",
      "VADER OUTPUT {'neg': 0.0, 'neu': 0.769, 'pos': 0.231, 'compound': 0.6597}\n",
      "positive\n",
      "\n",
      "INPUT SENTENCE My uncle's brother's neighbor's cat's veterinarian David reads the communist manifesto in his spare time.\n",
      "INPUT TO VADER ['my', 'uncle', \"'s\", 'brother', \"'s\", 'neighbor', \"'s\", 'cat', \"'s\", 'veterinarian', 'David', 'read', 'the', 'communist', 'manifesto', 'in', 'his', 'spare', 'time', '.']\n",
      "VADER OUTPUT {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "neutral\n",
      "\n",
      "INPUT SENTENCE He said that The Great Gatsby is the best novell ever, and I was about to throw hands.\n",
      "INPUT TO VADER ['he', 'say', 'that', 'the', 'Great', 'Gatsby', 'be', 'the', 'good', 'novell', 'ever', ',', 'and', 'I', 'be', 'about', 'to', 'throw', 'hand', '.']\n",
      "VADER OUTPUT {'neg': 0.0, 'neu': 0.579, 'pos': 0.421, 'compound': 0.8807}\n",
      "positive\n",
      "\n",
      "INPUT SENTENCE I could not look away from this train wrck of a movie, on February 14th of all days.\n",
      "INPUT TO VADER ['I', 'could', 'not', 'look', 'away', 'from', 'this', 'train', 'wrck', 'of', 'a', 'movie', ',', 'on', 'February', '14th', 'of', 'all', 'day', '.']\n",
      "VADER OUTPUT {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "neutral\n",
      "\n",
      "INPUT SENTENCE The film Everything Everywhere All At Once follows Evelyn Wang, a woman drowning under the stress of her family's failing laundromat.\n",
      "INPUT TO VADER ['the', 'film', 'everything', 'everywhere', 'all', 'at', 'once', 'follow', 'Evelyn', 'Wang', ',', 'a', 'woman', 'drown', 'under', 'the', 'stress', 'of', 'her', 'family', \"'s\", 'fail', 'laundromat', '.']\n",
      "VADER OUTPUT {'neg': 0.357, 'neu': 0.643, 'pos': 0.0, 'compound': -0.875}\n",
      "negative\n",
      "\n",
      "INPUT SENTENCE I just finished reading pride and prejudice which had me HOOOKED from the beginning.\n",
      "INPUT TO VADER ['I', 'just', 'finish', 'read', 'pride', 'and', 'prejudice', 'which', 'have', 'I', 'HOOOKED', 'from', 'the', 'beginning', '.']\n",
      "VADER OUTPUT {'neg': 0.21, 'neu': 0.637, 'pos': 0.153, 'compound': -0.2263}\n",
      "negative\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         4\n",
      "     neutral       0.33      0.33      0.33         3\n",
      "    positive       0.20      0.33      0.25         3\n",
      "\n",
      "    accuracy                           0.20        10\n",
      "   macro avg       0.18      0.22      0.19        10\n",
      "weighted avg       0.16      0.20      0.17        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gold =[]\n",
    "all_vader_output=[]\n",
    "target_names = ['negative', 'neutral', 'positive']\n",
    "for id_, sent in enumerate(path['text']):\n",
    "    #print(sent)\n",
    "    run_vader(sent,lemmatize=True, verbose=1)\n",
    "    print(vader_output_to_label(run_vader(sent, lemmatize=True)))\n",
    "    gold.append(path['sentiment'][id_])\n",
    "    #all_vader_output.append(vader_output_to_label(vader_model.polarity_scores(sent)))\n",
    "    all_vader_output.append(vader_output_to_label(run_vader(sent, lemmatize=True)))\n",
    "print(classification_report(gold, all_vader_output, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0386b72-7445-47ae-b557-b45da2954414",
   "metadata": {},
   "outputs": [],
   "source": [
    "pathnerc  = open('C:/Users/feter/OneDrive/Bureaublad/AI/AI Year 3/p4/text mining/train.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5290370-4037-4e96-9d81-49f1027d6e49",
   "metadata": {},
   "source": [
    "this was used as a test set\n",
    "https://www.kaggle.com/datasets/angevalli/entity-and-type-recognition-from-sentence?select=train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7bea90d-2038-4142-bd8c-a5845480a9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'words': 'EU'}, {'words': 'rejects'}, {'words': 'German'}, {'words': 'call'}, {'words': 'to'}, {'words': 'boycott'}, {'words': 'British'}, {'words': 'lamb'}, {'words': '.'}, {'words': 'The'}, {'words': 'European'}, {'words': 'Commission'}, {'words': 'said'}, {'words': 'on'}, {'words': 'Thursday'}, {'words': 'it'}, {'words': 'disagreed'}, {'words': 'with'}, {'words': 'German'}, {'words': 'advice'}, {'words': 'to'}, {'words': 'consumers'}, {'words': 'to'}, {'words': 'shun'}, {'words': 'British'}, {'words': 'lamb'}, {'words': 'until'}, {'words': 'scientists'}, {'words': 'determine'}, {'words': 'whether'}, {'words': 'mad'}, {'words': 'cow'}, {'words': 'disease'}, {'words': 'can'}, {'words': 'be'}, {'words': 'transmitted'}, {'words': 'to'}, {'words': 'sheep'}, {'words': '.'}, {'words': 'Germany'}, {'words': \"'s\"}, {'words': 'representative'}, {'words': 'to'}, {'words': 'the'}, {'words': 'European'}, {'words': 'Union'}, {'words': \"'s\"}, {'words': 'veterinary'}, {'words': 'committee'}, {'words': 'Werner'}, {'words': 'Zwingmann'}, {'words': 'said'}, {'words': 'on'}, {'words': 'Wednesday'}, {'words': 'consumers'}, {'words': 'should'}, {'words': 'buy'}, {'words': 'sheepmeat'}, {'words': 'from'}, {'words': 'countries'}, {'words': 'other'}, {'words': 'than'}, {'words': 'Britain'}, {'words': 'until'}, {'words': 'the'}, {'words': 'scientific'}, {'words': 'advice'}, {'words': 'was'}, {'words': 'clearer'}, {'words': '.'}, {'words': '\"'}, {'words': 'We'}, {'words': 'do'}, {'words': \"n't\"}, {'words': 'support'}, {'words': 'any'}, {'words': 'such'}, {'words': 'recommendation'}, {'words': 'because'}, {'words': 'we'}, {'words': 'do'}, {'words': \"n't\"}, {'words': 'see'}, {'words': 'any'}, {'words': 'grounds'}, {'words': 'for'}, {'words': 'it'}, {'words': ','}, {'words': '\"'}, {'words': 'the'}, {'words': 'Commission'}, {'words': \"'s\"}, {'words': 'chief'}, {'words': 'spokesman'}, {'words': 'Nikolaus'}, {'words': 'van'}, {'words': 'der'}, {'words': 'Pas'}, {'words': 'told'}, {'words': 'a'}]\n",
      "['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'B-PER', 'I-PER', 'I-PER', 'I-PER', 'O', 'O']\n",
      "203621 203621\n"
     ]
    }
   ],
   "source": [
    "training_features_kaggle = []\n",
    "training_gold_labels_kaggle = []\n",
    "for instance in pathnerc:\n",
    "    new_instance = instance.split()\n",
    "    \n",
    "    if len(new_instance) > 1:\n",
    "        a_dict = {'words': new_instance[0], \n",
    "       # add features\n",
    "        }\n",
    "        training_features_kaggle.append(a_dict)\n",
    "        training_gold_labels_kaggle.append(new_instance[1])\n",
    "print(training_features_kaggle[0:100]) \n",
    "print(training_gold_labels_kaggle[0:100])\n",
    "print(len(training_features_kaggle), len(training_gold_labels_kaggle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd809682-4e7c-418e-9651-19b1b0d5a8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pandas.read_csv('C:/Users/feter/OneDrive/Bureaublad/AI/AI Year 3/p4/text mining/NER-test.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5378df06-626c-4b08-b269-0769c89903ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'words': 'I'}, {'words': 'would'}, {'words': \"n't\"}, {'words': 'be'}, {'words': 'caught'}, {'words': 'dead'}, {'words': 'watching'}, {'words': 'the'}, {'words': 'NFL'}, {'words': 'if'}, {'words': 'it'}, {'words': 'were'}, {'words': \"n't\"}, {'words': 'for'}, {'words': 'Taylor'}, {'words': 'Swift'}, {'words': '.'}, {'words': 'Chris'}, {'words': \"O'Donnell\"}, {'words': 'stated'}, {'words': 'that'}, {'words': 'while'}, {'words': 'filming'}, {'words': 'for'}, {'words': 'this'}, {'words': 'movie'}, {'words': ','}, {'words': 'he'}, {'words': 'felt'}, {'words': 'like'}, {'words': 'he'}, {'words': 'was'}, {'words': 'in'}, {'words': 'a'}, {'words': 'Toys'}, {'words': \"''\"}, {'words': 'R'}, {'words': \"''\"}, {'words': 'Us'}, {'words': 'commercial'}, {'words': '.'}, {'words': 'The'}, {'words': 'whole'}, {'words': 'game'}, {'words': 'was'}, {'words': 'a'}, {'words': 'rollercoaster'}, {'words': 'ride'}, {'words': ','}, {'words': 'but'}, {'words': 'Los'}, {'words': 'Angeles'}, {'words': 'Lakers'}, {'words': 'ultimately'}, {'words': 'persevered'}, {'words': 'and'}, {'words': 'won'}, {'words': '!'}, {'words': 'Zendaya'}, {'words': 'slayed'}, {'words': 'in'}, {'words': 'Dune'}, {'words': '2'}, {'words': ','}, {'words': 'as'}, {'words': 'she'}, {'words': 'does'}, {'words': 'in'}, {'words': 'all'}, {'words': 'her'}, {'words': 'movies'}, {'words': '.'}, {'words': 'While'}, {'words': 'my'}, {'words': 'favorite'}, {'words': 'player'}, {'words': 'was'}, {'words': 'playing'}, {'words': 'this'}, {'words': 'match'}, {'words': 'and'}, {'words': 'started'}, {'words': 'off'}, {'words': 'strongggg'}, {'words': ','}, {'words': 'it'}, {'words': 'went'}, {'words': 'downhill'}, {'words': 'after'}, {'words': 'Messi'}, {'words': \"'s\"}, {'words': 'injyry'}, {'words': 'midgame'}, {'words': '.'}, {'words': 'My'}, {'words': 'uncle'}, {'words': \"'s\"}, {'words': 'brother'}, {'words': \"'s\"}, {'words': 'neighbor'}]\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'I-PERSON', 'O', 'B-PERSON', 'I-PERSON', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'B-PERSON', 'O', 'O', 'B-WORK_OF_ART', 'I-WORK_OF_ART', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "test_features_kaggle = []\n",
    "test_gold_labels_kaggle = []\n",
    "\n",
    "for instance in test['BIO NER tag']:\n",
    "    test_gold_labels_kaggle.append(instance)\n",
    "    \n",
    "for instance in test['token']:\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "        a_dict = {'words': instance, \n",
    "       # add features\n",
    "        }\n",
    "        test_features_kaggle.append(a_dict)\n",
    "        #training_gold_labels_kaggle.append(new_instance[1])\n",
    "print(test_features_kaggle[0:100]) \n",
    "print(test_gold_labels_kaggle[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f786853-3875-44d6-bd33-2549e7b85ee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(203814, 23652)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = DictVectorizer()\n",
    "concat_kaggle = training_features_kaggle + test_features_kaggle\n",
    "the_array = vec.fit_transform(concat_kaggle)\n",
    "#print(the_array)\n",
    "training_features_kaggle_split = the_array[0:len(training_features_kaggle)]\n",
    "test_features_kaggle_split = the_array[len(training_features_kaggle):]\n",
    "the_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9fc7a716-5e81-436a-945b-381964ff23f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_clf = svm.LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d49f550-20b7-4ea2-af2e-eb578f3ee60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "       B-DATE       0.00      0.00      0.00         1\n",
      "        B-LOC       0.00      0.00      0.00         0\n",
      "        B-ORG       0.00      0.00      0.00         3\n",
      "        B-PER       0.40      0.67      0.50         3\n",
      "     B-PERSON       0.00      0.00      0.00         3\n",
      "B-WORK_OF_ART       0.00      0.00      0.00         4\n",
      "       I-DATE       0.00      0.00      0.00         1\n",
      "        I-LOC       0.00      0.00      0.00         0\n",
      "        I-ORG       0.00      0.00      0.00         6\n",
      "        I-PER       0.00      0.00      0.00         1\n",
      "     I-PERSON       0.00      0.00      0.00         2\n",
      "I-WORK_OF_ART       0.00      0.00      0.00         9\n",
      "            O       0.87      1.00      0.93       160\n",
      "\n",
      "     accuracy                           0.84       193\n",
      "    macro avg       0.10      0.13      0.11       193\n",
      " weighted avg       0.73      0.84      0.78       193\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\feter\\onedrive\\bureaublad\\ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\feter\\onedrive\\bureaublad\\ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\feter\\onedrive\\bureaublad\\ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\feter\\onedrive\\bureaublad\\ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\feter\\onedrive\\bureaublad\\ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\feter\\onedrive\\bureaublad\\ai\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "lin_clf.fit(training_features_kaggle_split, training_gold_labels_kaggle)\n",
    "y_pred = lin_clf.predict(test_features_kaggle_split)\n",
    "print(classification_report(test_gold_labels_kaggle, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098d6ef3-1833-4bb3-b4f6-f86fcc4427a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
